[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=32
subdivisions=8
width=960
#height=540
height=512
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=100
max_batches = 500200
policy=steps
steps=400000, 450000
scales=0.1, 0.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#[convolutional]
#batch_normalize=1
#filters=64
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=32
filters=32
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#[convolutional]
#batch_normalize=1
#filters=128
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=64
filters=64
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=128
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=64
filters=64
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#[convolutional]
#batch_normalize=1
#filters=256
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=128
filters=128
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=256
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=128
filters=128
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#[convolutional]
#batch_normalize=1
#filters=512
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=256
filters=256
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=512
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=256
filters=256
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=512
#size=3
#stride=1
#pad=1
#activation=leaky

# Shortcut from here!
[convolutional]
batch_normalize=1
groups=256
filters=256
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#[convolutional]
#batch_normalize=1
#filters=1024
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=512
filters=512
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=1024
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=512
filters=512
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#filters=1024
#size=3
#stride=1
#pad=1
#activation=leaky

[convolutional]
batch_normalize=1
groups=512
filters=512
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky


#######

#[convolutional]
#batch_normalize=1
#size=3
#stride=1
#pad=1
#filters=1024
#activation=leaky

[convolutional]
batch_normalize=1
groups=1024
filters=1024
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky

#[convolutional]
#batch_normalize=1
#size=3
#stride=1
#pad=1
#filters=1024
#activation=leaky

[convolutional]
batch_normalize=1
groups=1024
filters=1024
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky

[route]
layers=-14

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=64
activation=leaky

[reorg]
stride=2

[route]
layers=-1,-4

#[convolutional]
#batch_normalize=1
#size=3
#stride=1
#pad=1
#filters=1024
#activation=leaky

[convolutional]
batch_normalize=1
groups=1024
filters=1024
size=3
stride=1
pad=1
activation=linear
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=80
activation=linear


[region]
anchors =  0.298,0.256, 0.602,0.566, 0.932,0.772, 1.225,1.190, 1.858,1.681, 1.895,0.854, 2.713,2.490, 3.381,1.460, 4.488,3.066, 7.450,5.975
bias_match=1
classes=3
coords=4
num=10
softmax=1
jitter=.2
rescore=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=0
thresh=0.5
random=0
